
A day to day plan

I followed https://github.com/prakhar21/100-Days-of-ML 


## Day-1 
* Learn about Pandas. [See Videos(1-5)](https://www.dataschool.io/easier-data-analysis-with-pandas/)
* Learn in general about ML [See Video (Blackbox Machine Learning)](https://www.youtube.com/watch?v=MsD28INtSv8)
* Read/Practice [Day-1 and Day-2](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
* See [Intro to Linear Regression](https://www.youtube.com/watch?v=zPG4NjIkCjc)
* Read [LR Docs](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)

## Day-2 
* Learn about Pandas. [See Videos(6-10)](https://www.dataschool.io/easier-data-analysis-with-pandas/)
* Learn in general about ML [See Video (Case Study: Churn Prediction)](https://www.youtube.com/watch?v=kE_t3Mm8Z50)
* Read/Practice [Day-3](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
* See [Data Spread](https://www.khanacademy.org/math/probability/data-distributions-a1/summarizing-spread-distributions/v/range-variance-and-standard-deviation-as-measures-of-dispersion)
* Andrew Ng [See Videos (1-3)](https://www.youtube.com/watch?v=-la3q9d7AKQ&list=PLNeKWBMsAzboR8vvhnlanxCNr2V7ITuxy)

## Day-3 
* Learn about Pandas. [See Videos(11-15)](https://www.dataschool.io/easier-data-analysis-with-pandas/)
* Learn in general about ML [See Video (Statistical Learning Theory)](https://www.youtube.com/watch?v=rqJ8SrnmWu0)
* Read/Practice [Day-4 and Day-8](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
* Visualization in Python [See Official Docs](https://matplotlib.org/users/pyplot_tutorial.html)

## Day-4 
* Learn about Pandas. [See Videos(16-18)](https://www.dataschool.io/easier-data-analysis-with-pandas/)
* Read [KNN-1](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)
* Read [KNN-2](https://medium.com/@adi.bronshtein/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7)

## Day-5 
* Learn about Pandas. [See Videos(19-22)](https://www.dataschool.io/easier-data-analysis-with-pandas/)
* Read/Practice [Day-7](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
* General read on [Medium](https://blog.usejournal.com/cracking-eaadhar-password-in-3-seconds-with-maths-9533c8e8f9c2)

## Day-6
* Learn about Pandas. [See Videos(23-26)](https://www.dataschool.io/easier-data-analysis-with-pandas/)
* Implementing KNN
* Read/Practice [Day-12](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
* KNN-Sklearn [See Official Docs](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)

## Day-7
* Learn about Numpy. [Read this](https://www.dataquest.io/blog/numpy-tutorial-python/)
* [Naive Bayes - 1](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/)
* [Naive Bayes - 2](https://medium.com/machine-learning-101/chapter-1-supervised-learning-and-naive-bayes-classification-part-1-theory-8b9e361897d5)
* [Naive Bayes - 3](https://machinelearningmastery.com/naive-bayes-for-machine-learning/)
* [Naive Bayes - 4](https://www.youtube.com/watch?v=6xBU74VWEuE)

## Day-8 
* [Lime](https://github.com/marcotcr/lime)
* [Building Trust in ML models](https://www.analyticsvidhya.com/blog/2017/06/building-trust-in-machine-learning-models/)
* [Interpretable ML models](https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime)
* Implementing Naive Bayes
* Learn in general about ML [See Video (Stochastic Gradient Descent)](https://www.youtube.com/watch?v=5TZww5bTROE) - 10 mins onwards

## Day-9 
* Lime hands-on news dataset
* Light read about [Averaging Ensemble Techniques](http://sebastianraschka.com/Articles/2014_ensemble_classifier.html) for more accurate predictions.
* Light reading on [Ensemble Techniques](https://www.dataquest.io/blog/introduction-to-ensembles/)
* Implementing Support Vector Machines
* See [Ensemble learners](https://www.youtube.com/watch?v=Un9zObFjBH0)

## Day-10 
* Implement Average Voting Ensemble Meta Model
* Read about [Stacking Ensemble Technique](https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html)
* Read [Stacking from scratch](https://machinelearningmastery.com/implementing-stacking-scratch-python/)
* Read [Stacking-concept-pictures-code](https://github.com/vecxoz/vecstack/blob/master/examples/00_stacking_concept_pictures_code.ipynb)

## Day-11 
* Read/Practice [Day-25](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2025%20Decision%20Tree.md)
* Read about [Feature Scaling](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)
* Read [Why, How and When to Scale](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)
* Implementation of Feature scaling techniques
* See [Decision Trees - MMDS](https://www.youtube.com/watch?v=NsUqRe-9tb4)
* Glance through [Decision Trees - Coursera](https://www.coursera.org/learn/ml-classification/home/week/3)

## Day-12 
* Implementing of Decision Trees
* See lectures from [Coursera - 2nd week](https://www.coursera.org/learn/ml-classification/home/week/2) and [Coursera - 4th week](https://www.coursera.org/learn/ml-classification/home/week/4)

## Day-13 
* Khan Academy [Vector's Section](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/vectors/v/vector-introduction-linear-algebra)
* Light read on [Stacking Classifier](https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/)
* Implementing - Handeling missing values using pandas
* General read on [EM for data imputation](https://www.theanalysisfactor.com/em-imputation-and-missing-data-is-mean-imputation-really-so-terrible/)

## Day-14 
* Read about [Model Evaluation](https://www.coursera.org/learn/ml-classification/home/week/6)
* See Khan Academy [Linear combinatations & span](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/linear-combinations/v/linear-combinations-and-span) and [Linear Dependence/Independence](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/linear-independence/v/linear-algebra-introduction-to-linear-independence)
* Explore a [Helper Lib](https://github.com/rasbt/mlxtend/)

## Day-15 
* See Khan Academy [Subspaces](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/subspace-basis/v/linear-subspaces)
* Practice [Mlxtend](https://github.com/rasbt/mlxtend/)
* Read/Practice [Day-33 & Day-34](https://github.com/Avik-Jain/100-Days-Of-ML-Code)

## Day-16 
* Light read on [Vector Quantization](https://machinelearningmastery.com/learning-vector-quantization-for-machine-learning/)
* Reading about [Boosting Algorithms](https://www.youtube.com/watch?v=wPqtzj5VZus)
* See all videos under [Ensembling](https://www.coursera.org/lecture/competitive-data-science/introduction-into-ensemble-methods-MJKCi)

## Day-17 
* Performance Metrics Hands-on
* Khan Academy [Vector dot products](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/dot-cross-products/v/vector-dot-product-and-vector-length)
* See [Metrics Optimization](https://www.coursera.org/learn/competitive-data-science/home/week/3)

## Day-18 
* General read on [Medium](https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e)
* Read about [Text Classification](https://medium.com/@ageitgey/text-classification-is-your-new-secret-weapon-7ca4fad15788)
* Read about [scrape method in Pandas](https://medium.com/@ageitgey/quick-tip-the-easiest-way-to-grab-data-out-of-a-web-page-in-python-7153cecfca58)
* Read about [FastText](https://research.fb.com/fasttext/)

## Day-19
* Glance through [Sklearn Docs on Feature Selection](http://scikit-learn.org/stable/modules/feature_selection.html)
* Read [Feature Selection - Analytics Vidhya](https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/)
* See [C2W1L4](https://www.youtube.com/watch?v=6g0t3Phly2M) and [C2W1L5](https://www.youtube.com/watch?v=NyG-7nRpsW8)
* Implementing Feature Selection Methods

## Day-20
* Explore [A fast and simple progress bar](https://github.com/tqdm/tqdm)
* Casual read on [Pandas - Tips/Tricks - 1](https://cambridgespark.com/content/tutorials/quick-panda-tricks/index.html) and [Pandas - Tips/Tricks - 2](https://towardsdatascience.com/pandas-tips-and-tricks-33bcc8a40bb9)
* See [Day 35](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
* Implement data resampling techniques

## Day-21 
* See all videos under [C2W2](https://www.youtube.com/watch?v=SjQyLhQIXSM&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=2)
* Implement saving/loading of ML models
* Write Dockerfile

## Day-22
* See and follow along [Introduction to PyTorch](https://www.youtube.com/watch?v=fJZew-fdNxw)
* Push Dockerfile and update Docker Readme.

## Day-23 
* Read Chapter 6 (till 6.1.2) from the book Mining Massive Datasets
* Read/Practice [Day-26](https://github.com/Avik-Jain/100-Days-Of-ML-Code)

## Day-24 
* Read Chapter 6 (till 6.1) from the book Mining Massive Datasets

## Day-25 
* Read/Practice [Day-27](https://github.com/Avik-Jain/100-Days-Of-ML-Code) and [Day-28](https://github.com/Avik-Jain/100-Days-Of-ML-Code)

## Day-26 
* See 1, 2, 3 videos from [Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
* See [Week-1 (Video by David Silver)](https://github.com/yandexdataschool/Practical_RL/tree/master/week1_intro)

## Day-27 
* Read about article on [RL 1, 2, 3, 4](https://medium.com/@prakhar.mishra)
* Implement randomised cartpole balancer

## Day-28 
* Read [paper](https://arxiv.org/pdf/1808.07913.pdf)
* Implement neural network in PyTorch
* PyTorch + TensorBoard
* Update Docker File/Image

## Day-29 
* See 4, 5, 6 videos from [Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
* See 1, 2, 3, 4 videos from [Linear Algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)

## Day-30 
* Implementing NN from scratch
* See 5, 6 videos from [Linear Algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)

## Day-31 
* Implement Cartpole using Cross Entropy method

## Day-32 
* Read about Q-Learning.
* See 7, 8, 9 videos from [Linear Algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
* See 7, 8 videos from [Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)

## Day-33 
* Read/Practice [Day 51](https://github.com/Avik-Jain/100-Days-Of-ML-Code)
* See [But what *is* a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk&t=7s)
* Read [Grammar correction in text](http://ww.panl10n.net/english/final%20reports/pdf%20files/Bangladesh/BAN21.pdf) usecase

## Day-34 
* See [How Neural Networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w&t=0s&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3)
* Read [Text Summarization](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.5237&rep=rep1&type=pdf)
* See 10, 11 videos from [Linear Algebra](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
* Read [Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/)

## Day-35 
* Implement Q-Learning

## Day-36
* Complete [Equations/Graphs/Functions](https://courses.edx.org/courses/course-v1:Microsoft+DAT256x+2T2018/courseware/72190688919b4f72a3e81a7fdbc4ec19/be5df94381c74baf8fdd83c36f71e0f0/?child=first)
* See 9, 10 videos from [Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)
* See [What does Backpropagation really do ?](https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3)

## Day-37 
* See [Backpropagation Calculus](https://www.youtube.com/watch?v=tIeHLnjs5U8&index=4&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
* See 1, 2, 3 from [Statistics - Khan Academy](https://www.youtube.com/watch?v=uhxtUt_-GyM&list=PL1328115D3D8A2566)

## Day-38 
* Read 7 in [Assignments](https://mlcourse.ai/assignments)
* See 4, 5, 6 from [Statistics - Khan Academy](https://www.youtube.com/watch?v=uhxtUt_-GyM&list=PL1328115D3D8A2566)

## Day-39 
* Read about Agglomerative Clustering

## Day-40 
* Read about Deep-Q-Networks and understand epsilon-greedy, replay buffer and target network in the same context.
* See 7, 8 from [Statistics - Khan Academy](https://www.youtube.com/watch?v=uhxtUt_-GyM&list=PL1328115D3D8A2566)

## Day-41 
* Read about Spectral Clustering
* See 9, 10, 11, 12 [Statistics - Khan Academy](https://www.youtube.com/watch?v=uhxtUt_-GyM&list=PL1328115D3D8A2566)
* Complete [Finance and Python](https://campus.datacamp.com/courses/importing-managing-financial-data-in-python/importing-stock-listing-data-from-excel)

## Day-42
* Read [Autoencoders Notebook](https://www.kaggle.com/shivamb/how-autoencoders-work-intro-and-usecases?utm_medium=social&utm_source=linkedin.com&utm_campaign=Weekly-Kernel-Awards)
* Complete [Week-1](https://www.coursera.org/learn/fundamentals-machine-learning-in-finance/home/week/1)

## Day-43 
* See [Neural Voice Cloning](https://www.youtube.com/watch?v=gVehTbi6Ipc&feature=youtu.be)
* Complete [Week-2](https://www.coursera.org/learn/fundamentals-machine-learning-in-finance/home/week/2)
* Read [Autoencoder in Text](https://www.doc.ic.ac.uk/~js4416/163/website/nlp/)

## Day-44
* Read 1-10 pages of [A Primer on Neural Network Modelsfor Natural Language Processing](http://u.cs.biu.ac.il/~yogo/nnlp.pdf)


